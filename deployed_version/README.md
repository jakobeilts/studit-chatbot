# **StudIT Chatbot RAG**

Dieses Repository stellt eine **Retrievalâ€‘Augmentedâ€‘Generation (RAG)**â€‘Pipeline bereit, die Fragen zu den ITâ€‘Services der Georgâ€‘Augustâ€‘UniversitÃ¤t GÃ¶ttingen beantwortet.

| Komponente/Notebook                | Zweck                                                                                                               |
| ---------------------------------- | ------------------------------------------------------------------------------------------------------------------- |
| `1_crawl.ipynb`                    | Crawlt Webseiten und speichert sichtbaren Text als `docs.pkl.gz`.                                                   |
| `2_chunk_and_store.ipynb`          | Zerteilt Texte, erstellt Embeddings und legt sie in einem lokalen **FAISS**â€‘Index (`faiss_wiki_index/`) ab.         |
| `3_retrieval_and_generation.ipynb` | Definiert Prompt, Retrievalâ€‘Nodes und Antwortâ€‘Generierung mithilfe von **LangGraph**.                               |
| `streamlit_app.py`                 | Interaktiver Chatbot auf Basis von **Qwen3â€‘32B**: RAGâ€‘Antworten, Quellenâ€‘Anzeige, Chatâ€‘Logging und Supportâ€‘Eâ€‘Mails. |

---

## 1. `1_crawl.ipynb`â€“ Webâ€‘Crawling (unverÃ¤ndert)

* Ruft alle URLs aus `helper.list_of_all_html.urls` ab.
* Entfernt unsichtbare Tags (`<script>`,`<style>` u.a.) in `extract_visible_text`.
* Speichert jede Seite als `langchain.docstore.document.Document` mit `metadata={"url": â€¦}`.
* Serialisiert die Liste gzipâ€‘komprimiert: **`docs.pkl.gz`**.

---

## 2. `2_chunk_and_store.ipynb`â€“ Chunking & FAISSâ€‘Index

1. **Laden** der Rohdokumente aus `docs.pkl.gz`.
2. **Chunking** mit `RecursiveCharacterTextSplitter` (`chunk_size=1000`, `chunk_overlap=200`).
3. **Embeddings** via **GWDG AcademicCloud API** (Konfiguration Ã¼ber `st.secrets`).
4. **Speichern** des FAISSâ€‘Vektorspeichers lokal: **`faiss_wiki_index/`**.

```python
embedder = AcademicCloudEmbeddings(
    api_key=st.secrets["GWDG_API_KEY"],
    url=st.secrets["BASE_URL_EMBEDDINGS"],
)
store = FAISS.from_documents(chunks, embedder)
store.save_local("faiss_wiki_index")
```

---

## 3. `3_retrieval_and_generation.ipynb` â€“ RAGâ€‘Orchestrierung (angepasst)

* **Promptâ€‘Vorlage** (Deutsch, kurz & zuverlÃ¤ssig) enthÃ¤lt jetzt das Directiveâ€‘Token `"/no_think"` und strengere Halluzinationsâ€‘Vermeidungsregeln.
* **LLM:** `qwen3â€‘32b` (Alibaba Qwen3) Ã¼ber die GWDGâ€‘API â€“ ersetzt `metaâ€‘llamaâ€‘3.1â€‘8bâ€‘instruct`.
* **LangGraphâ€‘State** hÃ¤lt Query, Kontextâ€‘Docs und Antworten; **MemorySaver** cacht den Graphâ€‘Zustand.
* **Retrievalâ€‘Tool** liefert jetzt sowohl serialisierten Quelltext **und** die Dokumentâ€‘Objekte zurÃ¼ck (`response_format="content_and_artifact"`).
* **Graph**: Queryâ†’(optional `retrieve`)â†’Answer.

```python
# LLMâ€‘Initialisierung (neu)
llm = init_chat_model(
    "qwen3-32b",
    model_provider="openai",
    base_url=st.secrets["BASE_URL"],
    temperature=0.3,
    api_key=st.secrets["GWDG_API_KEY"],
)

@tool(response_format="content_and_artifact")
def retrieve(query: str):
    """FAISSâ€‘Suche (k=2) und RÃ¼ckgabe der Treffer."""
    docs = vector_store.similarity_search(query, k=2)
    serialized = "\n\n".join(
        f"Source: {d.metadata}\nContent: {d.page_content}" for d in docs
    )
    return serialized, docs
```

---

## 4. `streamlit_app.py` â€“ Chatâ€‘Frontend & Supportâ€‘Workflow (neu)

| Bereich               | Ã„nderungen gegenÃ¼ber der VorgÃ¤ngerversion                                                                                               |
| --------------------- |-----------------------------------------------------------------------------------------------------------------------------------------|
| **Layout & Branding** | Neues Logo (`st.logo(...)`) und Ã¼berarbeitete Willkommensâ€‘Nachricht.                                                                    |
| **Chatâ€‘Engine**       | Verwendung von **Qwen3â€‘32B** via `init_chat_model`; Toolâ€‘Aufrufe Ã¼ber `llm.bind_tools([retrieve])`.                                     |
| **Caching**           | `@st.cache_resource` fÃ¼r die Graphâ€‘Kompilierung â€“ Startzeiten sinken.                                                                   |
| **Graphâ€‘Logik**       | Zwei LLMâ€‘Aufrufe: (1) Toolâ€‘Entscheidung, (2) finale Antwort; Kontext wird als separate AIâ€‘Message injiziert.                            |
| **Quellenâ€‘Anzeige**   | Dynamische Expander mit vollstÃ¤ndiger URL als Titel.                                                                                    |
| **Supportâ€‘Ticket**    | Formular in separater Funktion `support_form()`. HTMLâ€‘Eâ€‘Mails mit gebrandetem Kopfbereich; verbesserte Validierung und Fehlermeldungen. |
| **Logging**           | UnverÃ¤ndert: JSONLâ€‘Protokoll unter `chat_logs/`.                                                                                        |

### Schnelle Codeâ€‘Highlights

**Willkommensâ€‘Nachricht & Logo**

```python
st.set_page_config(page_title="StudITâ€‘Chatbot", page_icon="ðŸ’¬", layout="centered")
st.title("StudITâ€‘Chatbot")
st.logo("helper/images/uni_logo.png")
```

**Graphâ€‘Caching**

```python
@st.cache_resource(show_spinner="Initialisiere Modelleâ€¦")
def build_graph():
    ...
```

**Supportâ€‘Eâ€‘Mailâ€‘Versand** (unverÃ¤ndert, jetzt mit HTMLâ€‘Variante)

```python
def send_support_mail(subject, plain_body, html_body=None):
    cfg = st.secrets["EMAIL"]
    ...
```

---

## BenÃ¶tigte **Secrets** (unverÃ¤ndert)

```toml
# .streamlit/secrets.toml -----------------------------
GWDG_API_KEY        = "â€¦"
BASE_URL_EMBEDDINGS = "https://embedding-endpoint"
BASE_URL            = "https://llm-endpoint"

[EMAIL]
SMTP_SERVER = "mail.uni-goettingen.de"
SMTP_PORT   = "465"          # 465 = SMTPS, 587 = STARTTLS
SMTP_USER   = "chatbot@uni-goettingen.de"
SMTP_PASS   = "â€¦"
SUPPORT_TO  = "studIT-support@uni-goettingen.de"
```

---

## Installation & Start

```bash
# AbhÃ¤ngigkeiten
pip install -r requirements.txt

# Crawl â†’ Index â†’ StartÂ App
jupyter nbconvert --execute 1_crawl.ipynb
jupyter nbconvert --execute 2_chunk_and_store.ipynb
streamlit run streamlit_app.py
```

> **Tipp:** Die Notebooks 1 & 2 mÃ¼ssen nur erneut ausgefÃ¼hrt werden, wenn sich die Quellâ€‘Webseiten Ã¤ndern.

---

## Zusammenfassung

Die aktuelle StudITâ€‘RAGâ€‘Pipeline (Release 2025â€‘07)

* **crawlt**, **indexiert** und **beantwortet** Fragen zu ITâ€‘Services der UniversitÃ¤t GÃ¶ttingen,
* nutzt das leistungsstarke **Qwen3â€‘32Bâ€‘Modell** fÃ¼r prÃ¤zisere Antworten,
* bietet ein **komfortables Chatâ€‘Frontend** mit Quellenâ€‘Transparenz und gebrandetem Design,
* **loggt** sÃ¤mtliche Unterhaltungen vollautomatisch,
* und ermÃ¶glicht bei Bedarf den direkten **Supportâ€‘Kontakt per Eâ€‘Mail** â€“ inklusive strukturiertem HTMLâ€‘Layout und Chatâ€‘Zusammenfassung.

Durch Anpassung der URLâ€‘Liste bzw. des Prompts lÃ¤sst sich das System weiterhin problemlos auf andere Einrichtungen Ã¼bertragen.
